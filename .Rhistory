left
right
?t-test()
?t.test()
?sqtr()
n1<-10
n2<-10
m1<-3
m2<-5
s1<-sqrt(0.60)
s2<-sqrt(0.68)
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
a <- -2
s <- 2
n <- 9
error <- qt(0.975,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
a <- -2
s <- 2
n <- 9
error <- qt(0.995,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
a <- -2
s <- 2
n <- 9
error <- qt(0.95,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
a <- -2
s <- 2
n <- 9
error <- qt(0.975,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
a <- -2
s <- 2
n <- 9
error <- qt(0.975,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
right-left
a <- -2
s <- 2
n <- 9
error <- qt(0.95,df=n-1)*s/sqrt(n)
left <- a-error
right <- a+error
left
right
right-left
n1<-100
n2<-100
m1<-4
m2<-6
s1<-sqrt(0.50)
s2<-sqrt(2)
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-100
n2<-100
m1<-6
m2<-4
s1<-sqrt(2)
s2<-sqrt(0.5)
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-100
n2<-100
m1<-6
m2<-4
s1<-2
s2<-0.5
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-9
n2<-9
m1<--3
m2<-1
s1<-1.5
s2<-1.8
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-10
n2<-10
m1<-3
m2<-5
s1<-0.60
s2<-0.68
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-10
n2<-10
m1<-3
m2<-5
s1<-sqrt(0.60)
s2<-sqrt(0.68)
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
a<--3
a
n1<-9
n2<-9
m1<- -3
m2<-1
s1<-sqrt(1.5)
s2<-sqrt(1.8)
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-9
n2<-9
m1<- -3
m2<-1
s1<-1.5
s2<-1.8
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-9
n2<-9
m1<- -3
m2<-1
s1<-1.5
s2<-1.8
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
n1<-9
n2<-9
m1<- -3
m2<-1
s1<-1.5
s2<-1.8
N<-n1+n2-2
sp <- sqrt(((n1-1) * s1^2 + (n2-1) * s2^2) / N)
m1 - m2 + c(-1, 1) * qt(.975, 27) * sp * (1 / n1 + 1 / n2)^.5
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
p
install.packages("rmysql")
install.packages("RMySQL")
install.packages("Rtools")
Sys.setenv("MYSQL_HOME"="C:/Program Files/MySQL/MySQL Server 5.7")
install.packages("Rtools")
library(Rtools)
library(Rtools)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
data.lm = lm(y ~ x)
summary(data.lm)
data(mtcars)
data.lm = lm(mtcars$mpg ~ mtcars$weight)
names(mtcars)
data.lm = lm(mtcars$mpg ~ mtcars$wt)
newdata = data.frame(wt=mean(mtcars$wt)
newdata = data.frame(wt=mean(mtcars$wt))
newdata = data.frame(wt=mean(mtcars$wt))
predict(data.lm, newdata, interval="confidence")
data(mtcars)
data.lm = lm(mtcars$mpg ~ mtcars$wt)
a<-mean(mtcars$wt)
a
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="confidence")
summary(data.lm)
?predict.lm()
data(mtcars)
data.lm = lm(mtcars$mpg ~ mtcars$wt)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="predict")
data(mtcars)
data.lm = lm(mpg ~ $wt, data)
data.lm = lm(mpg ~ wt, data)
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="predict")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="predict")
?avarage()
data(mtcars)
data.lm = lm(wt ~ mpg, mtcars)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="predict")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="predict")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
a<-mean(mtcars$wt)
newdata = data.frame(wt=a)
predict(data.lm, newdata, interval="confidence")
?mtcars
summary(data.lm)
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=1000)
predict(data.lm, newdata, interval="confidence")
summary(data.lm)
data(mtcars)
data.lm = lm(wt ~ mpg, mtcars)
newdata = data.frame(wt=1361)
predict(data.lm, newdata, interval="confidence")
summary(data.lm)
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=1361)
predict(data.lm, newdata, interval="predictive")
newdata = data.frame(wt=1361)
predict(data.lm, newdata, interval="prediction")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=3000)
predict(data.lm, newdata, interval="prediction")
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=3)
predict(data.lm, newdata, interval="prediction")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(data.lm, newdata, interval="confidence")
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=3)
predict(data.lm, newdata, interval="confidence")
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2000)
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=1)
predict(data.lm, newdata, interval="confidence")
#QUestion 5
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2000)
predict(data.lm, newdata, interval="confidence")
summary(data.lm)
#QUestion 5
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=-2)
predict(data.lm, newdata, interval="confidence")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(data.lm, newdata, interval="confidence")
#QUestion 5
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(data.lm, newdata, interval="prediction")
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(data.lm, newdata, interval="confidence")
summary(data.lm)
data(mtcars)
fit = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(fit, newdata, interval="confidence")
summary(fit)
sumCoef <- summary(fit)$coefficient
sumCoef[1,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[1, 2]
data(mtcars)
fit = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(fit, newdata, interval="confidence")
summary(fit)
sumCoef <- summary(fit)$coefficient
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit3$df)*sumCoef[2,2]
sumCoef <- summary(fit)$coefficient
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
data.lm = lm(y ~ x)
summary(data.lm)
x2<-x/100
data.lm = lm(y ~ x2)
summary(data.lm)
x.1 <- rnorm(10000, mean = 0, sd = 5)
y.1 <- rnorm(10000, mean = 0, sd = 1)
X.1 <- c(x.1,-sum(x.1))
Y.1 <- c(y.1,-sum(y.1))
mean(x.1)
set.seed(1234)
x.1 <- rnorm(10000, mean = 0, sd = 5)
y.1 <- rnorm(10000, mean = 0, sd = 1)
X.1 <- c(x.1,-sum(x.1))
Y.1 <- c(y.1,-sum(y.1))
mean(x.1)
mean(y.1)
set.seed(1234)
x.1 <- rnorm(10000, mean = 0, sd = 5)
y.1 <- rnorm(10000, mean = 0, sd = 1)
X.1 <- c(x.1,-sum(x.1))
Y.1 <- c(y.1,-sum(y.1))
lm(Y.1 ~ X.1)
x.1<-x.1+10
lm(Y.1 ~ X.1)
x.1<-x.1+10000
lm(Y.1 ~ X.1)
#QUestion 5
data(mtcars)
data.lm = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=3)
predict(data.lm, newdata, interval="prediction")
summary(data.lm)
predict(data.lm, newdata, interval="prediction")
data(mtcars)
fit = lm(mpg ~ wt, mtcars)
newdata = data.frame(wt=2)
predict(fit, newdata, interval="confidence")
summary(fit)
sumCoef <- summary(fit)$coefficient
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit$df)*sumCoef[2,2]
mpg=mtcars$mpg
weight=mtcars$wt
weight2=2*weight
fit3<-lm(mpg~weight2)
sumCoef<-summary(fit3)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit3$df)*sumCoef[2,2]
mpg=mtcars$mpg
weight=mtcars$wt
weight2=weight/2
fit3<-lm(mpg~weight2)
sumCoef<-summary(fit3)$coefficients
sumCoef[2,1]+c(-1,1)*qt(.975,df=fit3$df)*sumCoef[2,2]
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
?createDataPartition()
names()
names(data)
names
names(AlzheimerDisease)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
summary(concrete)
table(cutcomp)
cutcomp<-cut2(training$CompressiveStrength,g=3)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
cutcomp<-cut2(training$CompressiveStrength,g=3)
table(cutcomp)
```{r}
fit<-glm(mpg~as.factor(cyl) + as.factor(vs) + as.factor(am) + as.factor(gear) + as.factor(carb) + disp + hp + drat + wt + qsec, data=mtcars)
summary(fit)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(fit1)
fit<-glm(mpg~as.factor(cyl) + as.factor(vs) + as.factor(am) + as.factor(gear) + as.factor(carb) + disp + hp + drat + wt + qsec, data=mtcars)
summary(fit)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(fit)
fit1<-glm(mpg ~ as.factor(cyl) + as.factor(am) + hp + wt, data=mtcars)
summary(fit1)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(fit1)
fit2<-glm(mpg ~ as.factor(am), data=mtcars)
summary(fit2)
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page
plot(fit2)
```{r}
fit<-glm(mpg~as.factor(cyl) + as.factor(vs) + as.factor(am) + as.factor(gear) + as.factor(carb) + disp + hp + drat + wt + qsec, data=mtcars)
summary(fit)
setwd("D:/Documents/Cursos/Data Products/Assessment")
deployApp()
library(shiny)
deployApp()
library(shinyapps)
deployApp()
shiny::runApp()
deployApp(appName = "Assessment")
deployApp(appName = "Assessment")
deployApp(appName = "Assessment")
shiny::runApp()
deployApp(appName = "Assessment")
deployApp(appName = "Assessment")
shiny::runApp()
shiny::runApp()
shiny::runApp()
deployApp(appName = "Assessment")
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
deployApp(appName = "Assessment")
library(slidify)
author("Task_LRB")
rm(list = ls()) #Clear all previous work
#Establecer el directorio de trabajo
setwd("D:/Documents/Formacion/Data_mining")
#Leer los datos
iris<-read.csv("iris.csv",header=FALSE)
#Nombre de las variables
colnames(iris)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
#Visionado rápido de los datos
head(iris) #Primeras filas
summary(iris) #Algunas medidas estadísticas
hist(iris$Petal.Length) #Histograma de una de la variable petal Length
boxplot(Sepal.Length~Species,data=iris) #Gráfico boxplot, útil para detectar outliers
library(MASS)
parcoord(iris[1:4],col=iris$Species)
library(lattice)
parallelplot(~iris[1:4]|Species,data=iris)
library(ggplot2)
qplot(Sepal.Length,Sepal.Width, data=iris,facets=Species ~.)
#DECISION TREE AND RANDOM FOREST
#División de los datos en training y testing (70% y 30% respectivamente)
str(iris)
set.seed(1234)
ind<-sample(2,nrow(iris),replace=TRUE,prob=c(0.7,0.3))
trainData<-iris[ind==1,]
testData<-iris[ind==2,]
#construir un árbol de decisión
#load package party
library(party)
myFormula<-Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
iris_ctree<-ctree(myFormula,data=trainData)
#check the prediction
table(predict(iris_ctree),trainData$Species)
#Rules
print(iris_ctree)
#ver el árbol
plot(iris_ctree)
plot(iris_ctree,type="simple")
#Verificar el arbol con los datos del test. Predecir
testPred<-predict(iris_ctree,newdata=testData)
table(testPred,testData$Species)
hola 5
plot(iris_ctree)
slidify("index.Rmd")
setwd("D:/Documents/Cursos/Data Products/Assessment/Task_LRB")
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
qplot(Sepal.Length,Sepal.Width, data=iris,facets=Species ~.)
pair(~iris[1:4]|Species,data=iris)
pairs(iris, panel=panel.smooth, main="Iris Data")
slidify("index.Rmd")
print(iris_ctree)
testPred<-predict(iris_ctree,newdata=testData)
#DECISION TREE AND RANDOM FOREST
#Divide the data into training and testing (70%/30%)
set.seed(1234)
ind<-sample(2,nrow(iris),replace=TRUE,prob=c(0.7,0.3))
trainData<-iris[ind==1,]
testData<-iris[ind==2,]
#Build the decision tree
#load package party
library(party)
myFormula<-Species~Sepal.Length+Sepal.Width+Petal.Length+Petal.Width
iris_ctree<-ctree(myFormula,data=trainData)
#check the prediction
table(predict(iris_ctree),trainData$Species)
testPred<-predict(iris_ctree,newdata=testData)
table(testPred,testData$Species)
slidify("index.Rmd")
